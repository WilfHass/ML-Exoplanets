{
	"optim":{
		"learning rate": 1e-5,
		"beta 1": 0.9,
		"beta 2": 0.999,
		"epsilon": 1e-8,
		"amsgrad": 0,
		"weight decay": 0.0
	},
	"training":{
		"num epochs": 50,
		"batch size": 64
	},
	"testing":{
		"batch size": 787
	},
	"output":{
		"tuned params" : "lr_1e-3_bs_64_beta1_0.999_50_epochs"
	}
}